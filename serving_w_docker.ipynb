{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import requests\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import altair as alt\n",
    "from ipywidgets import interact\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.feature_column as fc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "gender_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!kaggle competitions download -c titanic -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of data and exported models\n",
    "TRAIN_PATH = os.path.join('data', 'train.csv')\n",
    "TEST_PATH = os.path.join('data', 'test.csv')\n",
    "MODEL_DIR = os.path.join('model')\n",
    "EXPORT_DIR = os.path.join('savedmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "BUCKET_QUANTILES = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "CATEGORICAL_COLUMNS = ['Sex']\n",
    "NUMERIC_COLUMNS = ['Pclass', 'Fare']\n",
    "BUCKETIZED_COLUMNS = ['Age']\n",
    "FEATURES_COLUMNS = CATEGORICAL_COLUMNS + NUMERIC_COLUMNS + BUCKETIZED_COLUMNS\n",
    "\n",
    "TARGETS = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering columns\n",
    "FEATURE_CLIP_TRANS = ['Fare']\n",
    "FEATURE_LOG1P_TRANS = ['Fare']\n",
    "FEATURE_MIN_MAX_NORM = NUMERIC_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_PATH)\n",
    "df_test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 12), (179, 12), (418, 11))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the training data into training and validation sets \n",
    "df_train, df_valid = train_test_split(df, test_size=0.2, random_state=42, shuffle=True, stratify=df[TARGETS])\n",
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define data importing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(df, batch_size=10, num_epochs=None, shuffle=False, is_inference=False):\n",
    "    \n",
    "    features = df[FEATURES_COLUMNS]\n",
    "    features = {key: np.array(value) for key, value in dict(features).items()}\n",
    "\n",
    "    if not is_inference:\n",
    "        targets = df[TARGETS]\n",
    "        pairs = (features, targets)\n",
    "    else:\n",
    "        pairs = features\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(pairs) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=10000)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ({Sex: (None,), Pclass: (None,), Fare: (None,), Age: (None,)}, (None,)), types: ({Sex: tf.string, Pclass: tf.int64, Fare: tf.float64, Age: tf.float64}, tf.int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow Dataset\n",
    "ds = input_fn(df_train)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- batch index: 0\n",
      "---- feature Sex: [b'male' b'male' b'male' b'female' b'female' b'male' b'male' b'male'\n",
      " b'male' b'female']\n",
      "---- feature Pclass: [3 2 1 3 2 3 3 1 3 3]\n",
      "---- feature Fare: [ 56.4958   0.     221.7792   9.35    26.25     8.4333  56.4958 227.525\n",
      "   7.75    18.    ]\n",
      "---- feature Age: [nan nan nan 18. 31. 21. 26. nan nan 31.]\n",
      "---- targets: [1 0 0 1 1 0 1 0 1 0]\n",
      "\n",
      "-- batch index: 1\n",
      "---- feature Sex: [b'male' b'female' b'male' b'male' b'male' b'female' b'male' b'male'\n",
      " b'male' b'female']\n",
      "---- feature Pclass: [1 3 3 1 3 1 3 3 3 3]\n",
      "---- feature Fare: [35.5     9.825  69.55   26.55    7.8    90.      7.7333  7.25    6.45\n",
      " 25.4667]\n",
      "---- feature Age: [56. 21. nan 56. 21. 33. 21. nan 43. nan]\n",
      "---- targets: [1 0 0 0 0 1 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if we get desired input batches\n",
    "for i, sample in enumerate(ds.take(2)):\n",
    "    print('-- batch index: {}'.format(i))\n",
    "    for f in FEATURES_COLUMNS:\n",
    "        print('---- feature {}: {}'.format(f, sample[0][f]))\n",
    "    \n",
    "    print('---- targets: {}'.format(sample[1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data importing functions for our model at training, evaluation and predicting stage respectively.\n",
    "train_input_fn = functools.partial(input_fn, df_train, batch_size=64, num_epochs=100, shuffle=True)\n",
    "eval_input_fn = functools.partial(input_fn, df_valid, batch_size=64, num_epochs=1, shuffle=False)\n",
    "predict_input_fn = functools.partial(input_fn, df_test, batch_size=64, num_epochs=1, shuffle=False, is_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we encapsulate all preprocessing and transformation pipeline inside a `norm` func, which is gonna be passed to `tf.feature_columns` as an arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(tensor, feature_name, df, \n",
    "         clip_list=FEATURE_CLIP_TRANS, \n",
    "         log1p_list=FEATURE_LOG1P_TRANS, \n",
    "         minmax_list=FEATURE_MIN_MAX_NORM):\n",
    "    \n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    if feature_name in clip_list:\n",
    "        lower, upper = df[feature_name].quantile([0.05, 0.95])\n",
    "        df[feature_name] = df[feature_name].clip(lower=lower, upper=upper)\n",
    "        lower_b = tf.broadcast_to(tf.cast(lower, tensor.dtype), tf.shape(tensor))\n",
    "        upper_b = tf.broadcast_to(tf.cast(upper, tensor.dtype), tf.shape(tensor))\n",
    "        tensor = tf.where(tf.greater_equal(tensor, lower_b), tensor, lower_b)\n",
    "        tensor = tf.where(tf.less_equal(tensor, upper_b), tensor, upper_b)\n",
    "\n",
    "    if feature_name in log1p_list:\n",
    "        df[feature_name] = np.log1p(df[feature_name])\n",
    "        tensor = tf.math.log1p(tf.cast(tensor, tf.float32))\n",
    "        \n",
    "    if feature_name in minmax_list:\n",
    "        min_val, max_val = df[feature_name].min(), df[feature_name].max()\n",
    "        range_val = max_val - min_val\n",
    "        tensor = tf.truediv(\n",
    "            tf.subtract(tensor, tf.cast(min_val, tensor.dtype)), \n",
    "            tf.cast(range_val, tensor.dtype))\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_columns(df, categorical_columns=None, numeric_columns=None, bucketized_columns=None, bucket_quantiles=None):\n",
    "\n",
    "    feature_columns = []\n",
    "    \n",
    "    # Categorical features\n",
    "    if categorical_columns is not None:\n",
    "        for feature_name in categorical_columns:\n",
    "            vocab = df[feature_name].unique()\n",
    "            feature_columns.append(\n",
    "                fc.indicator_column(\n",
    "                    fc.categorical_column_with_vocabulary_list(feature_name, vocab, num_oov_buckets=1)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Numeric features\n",
    "    if numeric_columns is not None:\n",
    "        for feature_name in numeric_columns:\n",
    "            feature_columns.append(\n",
    "                fc.numeric_column(\n",
    "                    feature_name, \n",
    "                    default_value=0.0, \n",
    "                    dtype=tf.float32, \n",
    "                    normalizer_fn=lambda x, feature_name=feature_name, df=df: norm(x, feature_name, df)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Bucketized features\n",
    "    if bucketized_columns is not None and bucket_quantiles is not None:\n",
    "        for feature_name in bucketized_columns:\n",
    "            fc_num_to_bucket = fc.numeric_column(feature_name, default_value=0.0, dtype=tf.float32)\n",
    "            feature_columns.append(\n",
    "                fc.bucketized_column(\n",
    "                    fc_num_to_bucket,\n",
    "                    boundaries=df[feature_name].quantile(bucket_quantiles).values.tolist()\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = get_feature_columns(df_train, CATEGORICAL_COLUMNS, NUMERIC_COLUMNS, BUCKETIZED_COLUMNS, BUCKET_QUANTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=1)),\n",
       " NumericColumn(key='Pclass', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x10c66e048>),\n",
       " NumericColumn(key='Fare', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x10c66e0d0>),\n",
       " BucketizedColumn(source_column=NumericColumn(key='Age', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=None), boundaries=(19.0, 25.0, 32.0, 41.200000000000045))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0313 21:09:51.959619 4616410560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2758: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0313 21:09:51.961885 4616410560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2902: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0313 21:09:51.988204 4616410560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4307: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0313 21:09:51.988877 4616410560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4362: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape:  (10, 10)\n",
      "[[0.         0.         0.         0.         1.         0.7434285\n",
      "  1.         1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.\n",
      "  0.5        1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         1.\n",
      "  0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.         0.         0.09195788\n",
      "  1.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.4597527\n",
      "  0.5        0.         1.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.05672324\n",
      "  1.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.7434285\n",
      "  1.         1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         1.\n",
      "  0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.02815568\n",
      "  1.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.32274547\n",
      "  1.         0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def demo(feature_columns, take=1):\n",
    "    input_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "    for feature_batch, label_batch in ds.take(take):\n",
    "        batch = input_layer(feature_batch).numpy()\n",
    "        print('Batch shape: ', batch.shape)\n",
    "        print(batch)\n",
    "        \n",
    "\n",
    "# The column of transformed output maxtrix is sorted alphabetically by feature keys, \n",
    "# that is `Age` (None, 5) followed by `Fare` (None, 1), `Pclass` (None, 1) and lastly `Sex` (None, 2+1), total of 10, \n",
    "# not necessarily the same as the order columns we appended in `feature_columns` list\n",
    "demo(feature_columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_estimator = tf.estimator.LinearClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    model_dir=MODEL_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0313 21:09:52.007503 4616410560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0313 21:09:52.419514 4616410560 deprecation.py:506] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py:187: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x10c648240>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['global_step',\n",
       " 'linear/linear_model/Age_bucketized/weights',\n",
       " 'linear/linear_model/Age_bucketized/weights/part_0/Ftrl',\n",
       " 'linear/linear_model/Age_bucketized/weights/part_0/Ftrl_1',\n",
       " 'linear/linear_model/Fare/weights',\n",
       " 'linear/linear_model/Fare/weights/part_0/Ftrl',\n",
       " 'linear/linear_model/Fare/weights/part_0/Ftrl_1',\n",
       " 'linear/linear_model/Pclass/weights',\n",
       " 'linear/linear_model/Pclass/weights/part_0/Ftrl',\n",
       " 'linear/linear_model/Pclass/weights/part_0/Ftrl_1',\n",
       " 'linear/linear_model/Sex_indicator/weights',\n",
       " 'linear/linear_model/Sex_indicator/weights/part_0/Ftrl',\n",
       " 'linear/linear_model/Sex_indicator/weights/part_0/Ftrl_1',\n",
       " 'linear/linear_model/bias_weights',\n",
       " 'linear/linear_model/bias_weights/part_0/Ftrl',\n",
       " 'linear/linear_model/bias_weights/part_0/Ftrl_1']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00888481]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_value('linear/linear_model/Fare/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8221844 ],\n",
       "       [ 0.04628395],\n",
       "       [ 0.11746708],\n",
       "       [ 0.19993164],\n",
       "       [-0.22666484]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_value('linear/linear_model/Age_bucketized/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5573458], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_value('linear/linear_model/bias_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0313 21:09:55.345956 4616410560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7821229,\n",
       " 'accuracy_baseline': 0.61452514,\n",
       " 'auc': 0.83913046,\n",
       " 'auc_precision_recall': 0.7822344,\n",
       " 'average_loss': 0.47860998,\n",
       " 'label/mean': 0.38547486,\n",
       " 'loss': 0.47564396,\n",
       " 'precision': 0.8,\n",
       " 'prediction/mean': 0.3708927,\n",
       " 'recall': 0.5797101,\n",
       " 'global_step': 1200}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation results\n",
    "result = linear_estimator.evaluate(eval_input_fn)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'logits': array([-2.2154305], dtype=float32),\n",
       "  'logistic': array([0.09837335], dtype=float32),\n",
       "  'probabilities': array([0.90162665, 0.09837336], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-0.12374908], dtype=float32),\n",
       "  'logistic': array([0.46910214], dtype=float32),\n",
       "  'probabilities': array([0.53089786, 0.46910217], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object)}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dicts = list(linear_estimator.predict(predict_input_fn))\n",
    "pred_dicts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a31669d68>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The distribution of predicted survival likelihood in test dataset\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "classes = pd.Series([pred['class_ids'][0] for pred in pred_dicts])\n",
    "probs.plot(kind='hist', bins=20, title='predicted probabilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export `Estimator` to `SavedModel`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0313 21:09:56.843244 4616410560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0313 21:09:56.844172 4616410560 tf_logging.py:161] Export includes no default signature!\n"
     ]
    }
   ],
   "source": [
    "# Set serving input function before exporting our model and serving it\n",
    "features_raw_placeholder = {\n",
    "    'Sex': tf.keras.backend.placeholder(shape=(None, ), dtype=tf.string, name='input_sex'),\n",
    "    'Pclass': tf.keras.backend.placeholder(shape=(None, ), dtype=tf.float32, name='input_pclass'),\n",
    "    'Fare': tf.keras.backend.placeholder(shape=(None, ), dtype=tf.float32, name='input_fare'),\n",
    "    'Age': tf.keras.backend.placeholder(shape=(None, ), dtype=tf.float32, name='input_age')\n",
    "}\n",
    "\n",
    "serving_raw_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(\n",
    "    features=features_raw_placeholder)\n",
    "\n",
    "# Export the model\n",
    "export_path = linear_estimator.export_saved_model(\n",
    "    EXPORT_DIR, serving_raw_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If your input data at inference time is of serialized tf.Example format, then we can use a wrapper like below\n",
    "# serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "#     fc.make_parse_example_spec(feature_columns))\n",
    "#\n",
    "# export_path = linear_estimator.export_saved_model(\n",
    "#     EXPORT_DIR, serving_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['predict']\n"
     ]
    }
   ],
   "source": [
    "# Load the SavedModel back and find out what the default graph signature is, which will be used when inferencing\n",
    "loaded = tf.saved_model.load(export_path)\n",
    "print(list(loaded.signatures.keys())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic': <tf.Tensor 'IdentityN:2' shape=(None, 1) dtype=float32>, 'probabilities': <tf.Tensor 'IdentityN:4' shape=(None, 2) dtype=float32>, 'class_ids': <tf.Tensor 'IdentityN:0' shape=(None, 1) dtype=int64>, 'logits': <tf.Tensor 'IdentityN:3' shape=(None, 1) dtype=float32>, 'classes': <tf.Tensor 'IdentityN:1' shape=(None, 1) dtype=string>}\n"
     ]
    }
   ],
   "source": [
    "# The inferencing graph outputs' names\n",
    "infer = loaded.signatures[\"predict\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\n",
      "├── \u001b[01;34mdata\u001b[00m\n",
      "│   ├── gender_submission.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "├── \u001b[01;34mmodel\u001b[00m\n",
      "│   ├── checkpoint\n",
      "│   ├── \u001b[01;34meval\u001b[00m\n",
      "│   │   └── events.out.tfevents.1552482595.jameswj.local\n",
      "│   ├── events.out.tfevents.1552482592.jameswj.local\n",
      "│   ├── graph.pbtxt\n",
      "│   ├── model.ckpt-0.data-00000-of-00002\n",
      "│   ├── model.ckpt-0.data-00001-of-00002\n",
      "│   ├── model.ckpt-0.index\n",
      "│   ├── model.ckpt-0.meta\n",
      "│   ├── model.ckpt-1200.data-00000-of-00002\n",
      "│   ├── model.ckpt-1200.data-00001-of-00002\n",
      "│   ├── model.ckpt-1200.index\n",
      "│   └── model.ckpt-1200.meta\n",
      "├── \u001b[01;34msavedmodel\u001b[00m\n",
      "│   └── \u001b[01;34m1552482596\u001b[00m\n",
      "│       ├── saved_model.pb\n",
      "│       └── \u001b[01;34mvariables\u001b[00m\n",
      "│           ├── variables.data-00000-of-00002\n",
      "│           ├── variables.data-00001-of-00002\n",
      "│           └── variables.index\n",
      "└── serving_w_docker.ipynb\n",
      "\n",
      "6 directories, 20 files\n"
     ]
    }
   ],
   "source": [
    "# This is what our directory looks like now\n",
    "!tree ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serve the trained model with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ # Spin up a Docker container (container env defaults: model_dir => /models, default model_name => model)\n",
    "$ EXPORT_BASE_DIR=/Users/jameswong/WorkingDirectory/Python/labs/tf2/savedmodel/\n",
    "$ docker pull tensorflow/serving\n",
    "$ docker run -t --rm --name tf -p 8501:8501 -v \"$EXPORT_BASE_DIR:/models/model\" tensorflow/serving \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"outputs\": {\n",
      "        \"logistic\": [\n",
      "            [\n",
      "                0.0983734\n",
      "            ],\n",
      "            [\n",
      "                0.469102\n",
      "            ]\n",
      "        ],\n",
      "        \"class_ids\": [\n",
      "            [\n",
      "                0\n",
      "            ],\n",
      "            [\n",
      "                0\n",
      "            ]\n",
      "        ],\n",
      "        \"probabilities\": [\n",
      "            [\n",
      "                0.901627,\n",
      "                0.0983734\n",
      "            ],\n",
      "            [\n",
      "                0.530898,\n",
      "                0.469102\n",
      "            ]\n",
      "        ],\n",
      "        \"classes\": [\n",
      "            [\n",
      "                \"0\"\n",
      "            ],\n",
      "            [\n",
      "                \"0\"\n",
      "            ]\n",
      "        ],\n",
      "        \"logits\": [\n",
      "            [\n",
      "                -2.21543\n",
      "            ],\n",
      "            [\n",
      "                -0.123749\n",
      "            ]\n",
      "        ]\n",
      "    }\n",
      "}"
     ]
    }
   ],
   "source": [
    "# Upon being requested for inferencs, it throws back results the same as before\n",
    "!curl -d '{\"signature_name\":\"predict\",\"inputs\":{\"Sex\": [\"male\", \"female\"], \"Pclass\": [3, 3], \"Fare\": [7.8292,7.0000], \"Age\": [34.5, 47]}}' \\\n",
    "  -X POST http://localhost:8501/v1/models/model:predict             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputs': {'classes': [['0'], ['0']], 'logits': [[-2.21543], [-0.123749]], 'logistic': [[0.0983734], [0.469102]], 'class_ids': [[0], [0]], 'probabilities': [[0.901627, 0.0983734], [0.530898, 0.469102]]}}\n"
     ]
    }
   ],
   "source": [
    "# An alternative approach is to make predictions directly in Python\n",
    "data = '{\"signature_name\": \"predict\", \"inputs\": {\"Sex\": [\"male\", \"female\"], \"Pclass\": [3, 3], \"Fare\": [7.8292,7.0000], \"Age\": [34.5, 47]}}'\n",
    "url = 'http://localhost:8501/v1/models/model/versions/1552482596:predict'\n",
    "response = requests.post(url, data=data)\n",
    "\n",
    "if response.ok:\n",
    "    print(response.json())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52263dd85b6414fb01cbb1e13a02787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='male', description='sex'), IntSlider(value=1, description='pclass', max=3, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(sex='male', pclass=1, fare=100.0, age=8)\n",
    "def g(sex, pclass, fare, age):\n",
    "    data = '{'+f'\"Sex\": [\"{sex}\"], \"Pclass\": [{pclass}], \"Fare\": [{fare}], \"Age\": [{age}]'\n",
    "    data = f'\"inputs\": {data}'+'}'\n",
    "    data = '{'+f'\"signature_name\": \"predict\", {data}'+'}'\n",
    "\n",
    "    url = 'http://localhost:8501/v1/models/model/versions/1552482596:predict'\n",
    "    response = requests.post(url, data=data)\n",
    "\n",
    "    if response.ok:\n",
    "        prob = response.json()['outputs']['probabilities'][0][1]\n",
    "        print('Probabilities', prob)\n",
    "        source = pd.DataFrame({\n",
    "            'Output': ['Probabilities'],\n",
    "            'Probabilities': [prob]\n",
    "        })\n",
    "\n",
    "    return  alt.Chart(source).mark_bar().encode(\n",
    "        x=alt.X('Probabilities:Q', scale=alt.Scale(domain=(0.0, 1.0))),\n",
    "        y='Output'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
