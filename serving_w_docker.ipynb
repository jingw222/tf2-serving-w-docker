{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import requests\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.feature_column as fc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "gender_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!kaggle competitions download -c titanic -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of data and exported models\n",
    "TRAIN_PATH = os.path.join('data', 'train.csv')\n",
    "TEST_PATH = os.path.join('data', 'test.csv')\n",
    "MODEL_DIR = os.path.join('model')\n",
    "EXPORT_DIR = os.path.join('savedmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "BUCKET_QUANTILES = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "CATEGORICAL_COLUMNS = ['Sex']\n",
    "NUMERIC_COLUMNS = ['Pclass', 'Fare']\n",
    "BUCKETIZED_COLUMNS = ['Age']\n",
    "FEATURES_COLUMNS = CATEGORICAL_COLUMNS + NUMERIC_COLUMNS + BUCKETIZED_COLUMNS\n",
    "\n",
    "TARGETS = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering columns\n",
    "FEATURE_CLIP_TRANS = ['Fare']\n",
    "FEATURE_LOG1P_TRANS = ['Fare']\n",
    "FEATURE_MIN_MAX_NORM = NUMERIC_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_PATH)\n",
    "df_test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 12), (179, 12), (418, 11))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the training data into training and validation sets \n",
    "df_train, df_valid = train_test_split(df, test_size=0.2, random_state=42, shuffle=True, stratify=df[TARGETS])\n",
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define data importing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(df, batch_size=10, num_epochs=None, shuffle=False, is_inference=False):\n",
    "    \n",
    "    features = df[FEATURES_COLUMNS]\n",
    "    features = {key: np.array(value) for key, value in dict(features).items()}\n",
    "\n",
    "    if not is_inference:\n",
    "        targets = df[TARGETS]\n",
    "        pairs = (features, targets)\n",
    "    else:\n",
    "        pairs = features\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(pairs) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=10000)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ({Sex: (None,), Pclass: (None,), Fare: (None,), Age: (None,)}, (None,)), types: ({Sex: tf.string, Pclass: tf.int64, Fare: tf.float64, Age: tf.float64}, tf.int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow Dataset\n",
    "ds = input_fn(df_train)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- batch index: 0\n",
      "---- feature Sex: [b'male' b'male' b'male' b'female' b'female' b'male' b'male' b'male'\n",
      " b'male' b'female']\n",
      "---- feature Pclass: [3 2 1 3 2 3 3 1 3 3]\n",
      "---- feature Fare: [ 56.4958   0.     221.7792   9.35    26.25     8.4333  56.4958 227.525\n",
      "   7.75    18.    ]\n",
      "---- feature Age: [nan nan nan 18. 31. 21. 26. nan nan 31.]\n",
      "---- targets: [1 0 0 1 1 0 1 0 1 0]\n",
      "\n",
      "-- batch index: 1\n",
      "---- feature Sex: [b'male' b'female' b'male' b'male' b'male' b'female' b'male' b'male'\n",
      " b'male' b'female']\n",
      "---- feature Pclass: [1 3 3 1 3 1 3 3 3 3]\n",
      "---- feature Fare: [35.5     9.825  69.55   26.55    7.8    90.      7.7333  7.25    6.45\n",
      " 25.4667]\n",
      "---- feature Age: [56. 21. nan 56. 21. 33. 21. nan 43. nan]\n",
      "---- targets: [1 0 0 0 0 1 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if we get desired input batches\n",
    "for i, sample in enumerate(ds.take(2)):\n",
    "    print('-- batch index: {}'.format(i))\n",
    "    for f in FEATURES_COLUMNS:\n",
    "        print('---- feature {}: {}'.format(f, sample[0][f]))\n",
    "    \n",
    "    print('---- targets: {}'.format(sample[1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data importing functions for our model at training, evaluation and predicting stage respectively.\n",
    "train_input_fn = functools.partial(input_fn, df_train, batch_size=64, num_epochs=100, shuffle=True)\n",
    "eval_input_fn = functools.partial(input_fn, df_valid, batch_size=64, num_epochs=1, shuffle=False)\n",
    "predict_input_fn = functools.partial(input_fn, df_test, batch_size=64, num_epochs=1, shuffle=False, is_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we encapsulate all preprocessing and transformation pipeline inside a `norm` func, which is gonna be passed to `tf.feature_columns` as an arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(tensor, feature_name, df, \n",
    "         clip_list=FEATURE_CLIP_TRANS, \n",
    "         log1p_list=FEATURE_LOG1P_TRANS, \n",
    "         minmax_list=FEATURE_MIN_MAX_NORM):\n",
    "    \n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    if feature_name in clip_list:\n",
    "        lower, upper = df[feature_name].quantile([0.05, 0.95])\n",
    "        df[feature_name] = df[feature_name].clip(lower=lower, upper=upper)\n",
    "        lower_b = tf.broadcast_to(tf.cast(lower, tensor.dtype), tf.shape(tensor))\n",
    "        upper_b = tf.broadcast_to(tf.cast(upper, tensor.dtype), tf.shape(tensor))\n",
    "        tensor = tf.where(tf.greater_equal(tensor, lower_b), tensor, lower_b)\n",
    "        tensor = tf.where(tf.less_equal(tensor, upper_b), tensor, upper_b)\n",
    "\n",
    "    if feature_name in log1p_list:\n",
    "        df[feature_name] = np.log1p(df[feature_name])\n",
    "        tensor = tf.math.log1p(tf.cast(tensor, tf.float32))\n",
    "        \n",
    "    if feature_name in minmax_list:\n",
    "        min_val, max_val = df[feature_name].min(), df[feature_name].max()\n",
    "        range_val = max_val - min_val\n",
    "        tensor = tf.truediv(\n",
    "            tf.subtract(tensor, tf.cast(min_val, tensor.dtype)), \n",
    "            tf.cast(range_val, tensor.dtype))\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_columns(df, categorical_columns=None, numeric_columns=None, bucketized_columns=None, bucket_quantiles=None):\n",
    "\n",
    "    feature_columns = []\n",
    "    \n",
    "    # Categorical features\n",
    "    if categorical_columns is not None:\n",
    "        for feature_name in categorical_columns:\n",
    "            vocab = df[feature_name].unique()\n",
    "            feature_columns.append(\n",
    "                fc.indicator_column(\n",
    "                    fc.categorical_column_with_vocabulary_list(feature_name, vocab, num_oov_buckets=1)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Numeric features\n",
    "    if numeric_columns is not None:\n",
    "        for feature_name in numeric_columns:\n",
    "            feature_columns.append(\n",
    "                fc.numeric_column(\n",
    "                    feature_name, \n",
    "                    default_value=0.0, \n",
    "                    dtype=tf.float32, \n",
    "                    normalizer_fn=lambda x, feature_name=feature_name, df=df: norm(x, feature_name, df)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Bucketized features\n",
    "    if bucketized_columns is not None and bucket_quantiles is not None:\n",
    "        for feature_name in bucketized_columns:\n",
    "            fc_num_to_bucket = fc.numeric_column(feature_name, default_value=0.0, dtype=tf.float32)\n",
    "            feature_columns.append(\n",
    "                fc.bucketized_column(\n",
    "                    fc_num_to_bucket,\n",
    "                    boundaries=df[feature_name].quantile(bucket_quantiles).values.tolist()\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = get_feature_columns(df_train, CATEGORICAL_COLUMNS, NUMERIC_COLUMNS, BUCKETIZED_COLUMNS, BUCKET_QUANTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=1)),\n",
       " NumericColumn(key='Pclass', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x1128cfa60>),\n",
       " NumericColumn(key='Fare', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x1128cfae8>),\n",
       " BucketizedColumn(source_column=NumericColumn(key='Age', shape=(1,), default_value=(0.0,), dtype=tf.float32, normalizer_fn=None), boundaries=(19.0, 25.0, 32.0, 41.200000000000045))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0312 21:42:35.262887 4602074560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2758: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0312 21:42:35.264359 4602074560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2902: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0312 21:42:35.280864 4602074560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4307: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0312 21:42:35.281569 4602074560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4362: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape:  (10, 10)\n",
      "[[0.         0.         0.         0.         1.         0.7434285\n",
      "  1.         1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.\n",
      "  0.5        1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         1.\n",
      "  0.         1.         0.         0.        ]\n",
      " [1.         0.         0.         0.         0.         0.09195788\n",
      "  1.         0.         1.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.4597527\n",
      "  0.5        0.         1.         0.        ]\n",
      " [0.         1.         0.         0.         0.         0.05672324\n",
      "  1.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.7434285\n",
      "  1.         1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         1.\n",
      "  0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.02815568\n",
      "  1.         1.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.32274547\n",
      "  1.         0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def demo(feature_columns, take=1):\n",
    "    input_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "    for feature_batch, label_batch in ds.take(take):\n",
    "        batch = input_layer(feature_batch).numpy()\n",
    "        print('Batch shape: ', batch.shape)\n",
    "        print(batch)\n",
    "        \n",
    "\n",
    "# The column of transformed output maxtrix is sorted alphabetically by feature keys, \n",
    "# that is `Age` (None, 5) followed by `Fare` (None, 1), `Pclass` (None, 1) and lastly `Sex` (None, 2+1), total of 10, \n",
    "# not necessarily the same as the order columns we appended in `feature_columns` list\n",
    "demo(feature_columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_estimator = tf.estimator.LinearClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    model_dir=MODEL_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0312 21:42:35.301193 4602074560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:238: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0312 21:42:35.726919 4602074560 deprecation.py:506] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py:187: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0312 21:42:35.958639 4602074560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0312 21:42:35.991600 4602074560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x1128cdf28>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['global_step',\n",
       " 'linear/linear_model/Age_bucketized/weights',\n",
       " 'linear/linear_model/Age_bucketized/weights/part_0/Ftrl',\n",
       " 'linear/linear_model/Age_bucketized/weights/part_0/Ftrl_1',\n",
       " 'linear/linear_model/Fare/weights',\n",
       " 'linear/linear_model/Fare/weights/part_0/Ftrl',\n",
       " 'linear/linear_model/Fare/weights/part_0/Ftrl_1',\n",
       " 'linear/linear_model/Pclass/weights',\n",
       " 'linear/linear_model/Pclass/weights/part_0/Ftrl',\n",
       " 'linear/linear_model/Pclass/weights/part_0/Ftrl_1',\n",
       " 'linear/linear_model/Sex_indicator/weights',\n",
       " 'linear/linear_model/Sex_indicator/weights/part_0/Ftrl',\n",
       " 'linear/linear_model/Sex_indicator/weights/part_0/Ftrl_1',\n",
       " 'linear/linear_model/bias_weights',\n",
       " 'linear/linear_model/bias_weights/part_0/Ftrl',\n",
       " 'linear/linear_model/bias_weights/part_0/Ftrl_1']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25761795]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_value('linear/linear_model/Fare/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87398267],\n",
       "       [ 0.16752891],\n",
       "       [ 0.14393766],\n",
       "       [ 0.22214134],\n",
       "       [-0.19652022]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_value('linear/linear_model/Age_bucketized/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6896507], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.get_variable_value('linear/linear_model/bias_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7821229,\n",
       " 'accuracy_baseline': 0.61452514,\n",
       " 'auc': 0.83695656,\n",
       " 'auc_precision_recall': 0.78446585,\n",
       " 'average_loss': 0.47682607,\n",
       " 'label/mean': 0.38547486,\n",
       " 'loss': 0.47396708,\n",
       " 'precision': 0.8,\n",
       " 'prediction/mean': 0.3775963,\n",
       " 'recall': 0.5797101,\n",
       " 'global_step': 2400}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation results\n",
    "result = linear_estimator.evaluate(eval_input_fn)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'logits': array([-2.2212594], dtype=float32),\n",
       "  'logistic': array([0.09785759], dtype=float32),\n",
       "  'probabilities': array([0.9021424 , 0.09785757], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-0.00565559], dtype=float32),\n",
       "  'logistic': array([0.49858612], dtype=float32),\n",
       "  'probabilities': array([0.5014139, 0.4985861], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object)}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dicts = list(linear_estimator.predict(predict_input_fn))\n",
    "pred_dicts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a375cf358>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The distribution of predicted survival likelihood in test dataset\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "classes = pd.Series([pred['class_ids'][0] for pred in pred_dicts])\n",
    "probs.plot(kind='hist', bins=20, title='predicted probabilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export `Estimator` to `SavedModel`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0312 21:42:40.085338 4602074560 deprecation.py:323] From /Users/jameswong/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0312 21:42:40.086337 4602074560 tf_logging.py:161] Export includes no default signature!\n"
     ]
    }
   ],
   "source": [
    "# Set serving input function before exporting our model and serving it\n",
    "features_raw_placeholder = {\n",
    "    'Sex': tf.keras.backend.placeholder(shape=(None, ), dtype=tf.string, name='input_sex'),\n",
    "    'Pclass': tf.keras.backend.placeholder(shape=(None, ), dtype=tf.float32, name='input_pclass'),\n",
    "    'Fare': tf.keras.backend.placeholder(shape=(None, ), dtype=tf.float32, name='input_fare'),\n",
    "    'Age': tf.keras.backend.placeholder(shape=(None, ), dtype=tf.float32, name='input_age')\n",
    "}\n",
    "\n",
    "serving_raw_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(\n",
    "    features=features_raw_placeholder)\n",
    "\n",
    "# Export the model\n",
    "export_path = linear_estimator.export_saved_model(\n",
    "    EXPORT_DIR, serving_raw_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If your input data at inference time is of serialized tf.Example format, then we can use a wrapper like below\n",
    "# serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "#     fc.make_parse_example_spec(feature_columns))\n",
    "#\n",
    "# export_path = linear_estimator.export_saved_model(\n",
    "#     EXPORT_DIR, serving_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['predict']\n"
     ]
    }
   ],
   "source": [
    "# Load the SavedModel back and find out what the default graph signature is, which will be used when inferencing\n",
    "loaded = tf.saved_model.load(export_path)\n",
    "print(list(loaded.signatures.keys())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic': <tf.Tensor 'IdentityN:2' shape=(None, 1) dtype=float32>, 'probabilities': <tf.Tensor 'IdentityN:4' shape=(None, 2) dtype=float32>, 'class_ids': <tf.Tensor 'IdentityN:0' shape=(None, 1) dtype=int64>, 'logits': <tf.Tensor 'IdentityN:3' shape=(None, 1) dtype=float32>, 'classes': <tf.Tensor 'IdentityN:1' shape=(None, 1) dtype=string>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "infer = loaded.signatures[\"predict\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\n",
      "├── \u001b[01;34mdata\u001b[00m\n",
      "│   ├── gender_submission.csv\n",
      "│   ├── test.csv\n",
      "│   └── train.csv\n",
      "├── \u001b[01;34mmodel\u001b[00m\n",
      "│   ├── checkpoint\n",
      "│   ├── \u001b[01;34meval\u001b[00m\n",
      "│   │   ├── events.out.tfevents.1552395498.jameswj.local\n",
      "│   │   └── events.out.tfevents.1552398159.jameswj.local\n",
      "│   ├── events.out.tfevents.1552395495.jameswj.local\n",
      "│   ├── events.out.tfevents.1552398155.jameswj.local\n",
      "│   ├── graph.pbtxt\n",
      "│   ├── model.ckpt-0.data-00000-of-00002\n",
      "│   ├── model.ckpt-0.data-00001-of-00002\n",
      "│   ├── model.ckpt-0.index\n",
      "│   ├── model.ckpt-0.meta\n",
      "│   ├── model.ckpt-1200.data-00000-of-00002\n",
      "│   ├── model.ckpt-1200.data-00001-of-00002\n",
      "│   ├── model.ckpt-1200.index\n",
      "│   ├── model.ckpt-1200.meta\n",
      "│   ├── model.ckpt-2400.data-00000-of-00002\n",
      "│   ├── model.ckpt-2400.data-00001-of-00002\n",
      "│   ├── model.ckpt-2400.index\n",
      "│   └── model.ckpt-2400.meta\n",
      "├── \u001b[01;34msavedmodel\u001b[00m\n",
      "│   ├── \u001b[01;34m1552395499\u001b[00m\n",
      "│   │   ├── saved_model.pb\n",
      "│   │   └── \u001b[01;34mvariables\u001b[00m\n",
      "│   │       ├── variables.data-00000-of-00002\n",
      "│   │       ├── variables.data-00001-of-00002\n",
      "│   │       └── variables.index\n",
      "│   └── \u001b[01;34m1552398159\u001b[00m\n",
      "│       ├── saved_model.pb\n",
      "│       └── \u001b[01;34mvariables\u001b[00m\n",
      "│           ├── variables.data-00000-of-00002\n",
      "│           ├── variables.data-00001-of-00002\n",
      "│           └── variables.index\n",
      "└── serving_w_docker.ipynb\n",
      "\n",
      "8 directories, 30 files\n"
     ]
    }
   ],
   "source": [
    "# This is what our directory looks like now\n",
    "!tree ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serve the trained model with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ # Spin up a Docker container (container env defaults: model_dir => /models, default model_name => model)\n",
    "$ EXPORT_BASE_DIR=/Users/jameswong/WorkingDirectory/Python/labs/tf2/savedmodel/\n",
    "$ docker run -t --rm --name tf -p 8501:8501 -v \"$EXPORT_BASE_DIR:/models/model\" tensorflow/serving \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"outputs\": {\n",
      "        \"logistic\": [\n",
      "            [\n",
      "                0.0978576\n",
      "            ],\n",
      "            [\n",
      "                0.498586\n",
      "            ]\n",
      "        ],\n",
      "        \"class_ids\": [\n",
      "            [\n",
      "                0\n",
      "            ],\n",
      "            [\n",
      "                0\n",
      "            ]\n",
      "        ],\n",
      "        \"probabilities\": [\n",
      "            [\n",
      "                0.902142,\n",
      "                0.0978576\n",
      "            ],\n",
      "            [\n",
      "                0.501414,\n",
      "                0.498586\n",
      "            ]\n",
      "        ],\n",
      "        \"classes\": [\n",
      "            [\n",
      "                \"0\"\n",
      "            ],\n",
      "            [\n",
      "                \"0\"\n",
      "            ]\n",
      "        ],\n",
      "        \"logits\": [\n",
      "            [\n",
      "                -2.22126\n",
      "            ],\n",
      "            [\n",
      "                -0.00565559\n",
      "            ]\n",
      "        ]\n",
      "    }\n",
      "}"
     ]
    }
   ],
   "source": [
    "# Upon being requested for inferencs, it throws back results the same as before\n",
    "!curl -d '{\"signature_name\":\"predict\",\"inputs\":{\"Sex\": [\"male\", \"female\"], \"Pclass\": [3, 3], \"Fare\": [7.8292,7.0000], \"Age\": [34.5, 47]}}' \\\n",
    "  -X POST http://localhost:8501/v1/models/model:predict             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputs': {'class_ids': [[0], [0]], 'probabilities': [[0.902142, 0.0978576], [0.501414, 0.498586]], 'classes': [['0'], ['0']], 'logits': [[-2.22126], [-0.00565559]], 'logistic': [[0.0978576], [0.498586]]}}\n"
     ]
    }
   ],
   "source": [
    "# An alternative approach is to make predictions directly in Python\n",
    "data = '{\"signature_name\": \"predict\", \"inputs\": {\"Sex\": [\"male\", \"female\"], \"Pclass\": [3, 3], \"Fare\": [7.8292,7.0000], \"Age\": [34.5, 47]}}'\n",
    "url = 'http://localhost:8501/v1/models/model/versions/1552398159:predict'\n",
    "response = requests.post(url, data=data)\n",
    "\n",
    "if response.ok:\n",
    "    print(response.json())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
